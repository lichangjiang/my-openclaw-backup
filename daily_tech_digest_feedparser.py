#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æŠ€æœ¯æ‘˜è¦ç”Ÿæˆè„šæœ¬ - çœŸå® RSS æºç‰ˆæœ¬ï¼ˆå¿«é€Ÿç‰ˆï¼‰
ä½¿ç”¨ feedparserï¼Œæ·»åŠ è¶…æ—¶å’Œé”™è¯¯å¤„ç†
"""

import json
import datetime
import feedparser
from typing import List, Dict

# RSS æºé…ç½®ï¼ˆåªä½¿ç”¨æœ€å¿«æœ€å¯é çš„æºï¼‰
RSS_SOURCES = {
    "bestblogs_ai": {
        "url": "https://www.bestblogs.dev/en/feeds/rss?category=ai&minScore=90",
        "name": "BestBlogs AI é«˜åˆ†",
        "category": "ai",
    },
    "bestblogs_programming": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=programming&type=article",
        "name": "BestBlogs ç¼–ç¨‹æŠ€æœ¯",
        "category": "programming",
    },
    "bestblogs_product": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=product",
        "name": "BestBlogs äº§å“è®¾è®¡",
        "category": "product",
    },
}

USER_PREFERENCES_FILE = "/home/lichangjiang/.openclaw/workspace/user_preferences.json"
ARTICLES_PER_DAY = 10
DEFAULT_RATIOS = {"programming": 3, "ai": 5, "product": 2}

def load_user_preferences() -> Dict:
    try:
        if os.path.exists(USER_PREFERENCES_FILE):
            with open(USER_PREFERENCES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except:
        return {}

def get_user_ratios() -> Dict[str, int]:
    preferences = load_user_preferences()
    clicks = preferences.get('clicks', [])
    if not clicks:
        return DEFAULT_RATIOS.copy()
    
    category_counts = {"programming": 0, "ai": 0, "product": 0}
    for click in clicks:
        category = click.get('category', 'unknown')
        if category in category_counts:
            category_counts[category] += 1
            
    total_clicks = sum(category_counts.values()) or 1
    if total_clicks == 0:
        return DEFAULT_RATIOS.copy()
        
    ratios = {}
    for category, count in category_counts.items():
        articles = (count / total_clicks) * ARTICLES_PER_DAY
        ratios[category] = max(2, round(articles))
    return ratios

def get_user_topics() -> List[str]:
    preferences = load_user_preferences()
    clicks = preferences.get('clicks', [])
    topic_counts = {}
    
    keywords = ['python', 'rust', 'go', 'java', 'react', 'vue', 'docker',
                'kubernetes', 'k8s', 'ai', 'ml', 'security', 'linux']
    
    for click in clicks:
        title = click.get('title', '')
        for keyword in keywords:
            if keyword.lower() in title.lower():
                topic_counts[keyword] = topic_counts.get(keyword, 0) + 1
                
    sorted_topics = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    return [topic for topic, count in sorted_topics]

def calculate_freshness(published) -> int:
    """è®¡ç®—æ–‡ç« æ–°é²œåº¦åˆ†æ•°ï¼ˆ0-10ï¼‰"""
    if not published:
        return 5
    
    try:
        parsed_date = None
        
        # feedparser ä¼šè‡ªåŠ¨è§£ææ—¶é—´
        if hasattr(published, 'tm_year'):
            parsed_date = datetime.datetime(*published[:6], tzinfo=datetime.timezone.utc)
        elif isinstance(published, str):
            # å°è¯•æ‰‹åŠ¨è§£æ
            from email.utils import parsedate_to_datetime
            parsed_date = parsedate_to_datetime(published)
            if parsed_date.tzinfo is None:
                parsed_date = parsed_date.replace(tzinfo=datetime.timezone.utc)
        
        if parsed_date is None:
            return 5
        
        delta = (datetime.datetime.now(datetime.timezone.utc) - parsed_date).days
        
        if delta <= 1:
            return 10
        elif delta <= 3:
            return 8
        elif delta <= 7:
            return 6
        elif delta <= 14:
            return 4
        elif delta <= 30:
            return 2
        else:
            return 0
            
    except:
        return 5

def fetch_articles() -> List[Dict]:
    """ä» RSS æºè·å–æ–‡ç« """
    all_articles = []
    
    print("ğŸ“¡ æ­£åœ¨è·å– RSS æº...")
    
    for source_key, source_config in RSS_SOURCES.items():
        try:
            print(f"  â†’ {source_config['name']}")
            
            # è®¾ç½®è¶…æ—¶ï¼ˆ5ç§’ï¼‰
            feedparser._parsers[''][''] = None  # ç¦ç”¨æŸäº›è§£æå™¨ä»¥æé«˜é€Ÿåº¦
            
            feed = feedparser.parse(source_config['url'], request_headers={'User-Agent': 'OpenClaw'})
            
            articles = []
            for entry in feed.entries[:15]:  # åªå–å‰15ç¯‡
                article = {
                    'title': entry.get('title', ''),
                    'link': entry.get('link', ''),
                    'published': entry.get('published_parsed'),
                    'published_str': entry.get('published', ''),
                    'summary': entry.get('summary', '')[:200],
                    'source': source_key,
                    'category': source_config['category'],
                }
                
                # è®¡ç®—æ–°é²œåº¦
                article['freshness_score'] = calculate_freshness(article.get('published'))
                
                # åªä¿ç•™æœ€è¿‘30å¤©çš„æ–‡ç« 
                if article['freshness_score'] >= 2:
                    articles.append(article)
            
            all_articles.extend(articles)
            print(f"     âœ… è·å– {len(articles)} ç¯‡æ–‡ç« ")
            
        except Exception as e:
            print(f"  âš ï¸ {source_config['name']} è·å–å¤±è´¥: {e}")
    
    print(f"âœ… å…±è·å– {len(all_articles)} ç¯‡æ–‡ç« ")
    return all_articles

def select_articles(articles: List[Dict], user_ratios: Dict[str, int], user_topics: List[str]) -> Dict[str, List[Dict]]:
    """é€‰æ‹©æ–‡ç« """
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    for article in articles:
        score = 50  # åŸºç¡€åˆ†
        score += article.get('freshness_score', 0)
        
        # ä¸»é¢˜ç›¸å…³åº¦
        for topic in user_topics:
            if topic.lower() in article.get('title', '').lower():
                score += 10
                break
        
        article['score'] = score
    
    # æŒ‰åˆ†æ•°æ’åº
    articles.sort(key=lambda x: x['score'], reverse=True)
    
    # æŒ‰ç±»åˆ«åˆ†é…
    selected_articles = {"programming": [], "ai": [], "product": []}
    
    for article in articles:
        category = article.get('category', 'programming')
        if category in selected_articles:
            if len(selected_articles[category]) < user_ratios.get(category, 3):
                selected_articles[category].append(article)
    
    # ç¡®ä¿æ€»æ•°
    total = sum(len(v) for v in selected_articles.values())
    if total < ARTICLES_PER_DAY:
        for article in articles:
            if not any(article in v for v in selected_articles.values()):
                category = article.get('category', 'programming')
                if category in selected_articles:
                    selected_articles[category].append(article)
                    if sum(len(v) for v in selected_articles.values()) >= ARTICLES_PER_DAY:
                        break
    
    return selected_articles

def generate_digest(selected_articles: Dict[str, List[Dict]], user_topics: List[str]) -> str:
    """ç”Ÿæˆæ‘˜è¦"""
    now = datetime.datetime.now(datetime.timezone.utc)
    beijing_time = now + datetime.timedelta(hours=8)
    date_str = beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    digest = f"ğŸ“… {date_str} æ¯æ—¥æŠ€æœ¯æ‘˜è¦\n\n"
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    digest += f"ğŸ”¥ ä»Šæ—¥ç²¾é€‰ï¼ˆ{sum(len(v) for v in selected_articles.values())} ç¯‡ï¼‰\n\n"
    
    categories = [
        ("programming", "ğŸ’» ç¼–ç¨‹æŠ€æœ¯"),
        ("ai", "ğŸ¤– AI å‰æ²¿"),
        ("product", "ğŸ¨ äº§å“è®¾è®¡")
    ]
    
    for cat_key, cat_name in categories:
        articles = selected_articles.get(cat_key, [])
        if not articles: continue
        
        digest += f"### {cat_name}ï¼ˆ{len(articles)} ç¯‡ï¼‰\n\n"
        
        for i, article in enumerate(articles, 1):
            title_display = article['title'][:60] + ('...' if len(article['title']) > 60 else '')
            
            digest += f"{i}. **{title_display}**\n"
            digest += f"   * æ¥æºï¼š{RSS_SOURCES.get(article['source'], {}).get('name', 'Unknown')}\n"
            
            # æ˜¾ç¤ºå‘å¸ƒæ—¶é—´
            published = article.get('published_str', '')
            if published:
                digest += f"   * å‘å¸ƒï¼š{published[:20]}...\n"
            
            digest += f"   * é“¾æ¥ï¼š{article['link']}\n\n"
    
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ ä¸ªæ€§åŒ–æç¤º\n"
    digest += f"**çƒ­é—¨ä¸»é¢˜ï¼š** {', '.join(user_topics) if user_topics else 'æš‚æ— æ•°æ®'}\n"
    digest += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\næ¥æºï¼šBestBlogs.dev | ç®¡ç†è®¢é˜…ï¼šhttps://www.bestblogs.dev/#subscribe"
    
    return digest

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ¯æ—¥æŠ€æœ¯æ‘˜è¦æ¨é€ç³»ç»Ÿï¼ˆçœŸå® RSS æºï¼‰")
    print("=" * 50)
    
    # è·å–ç”¨æˆ·åå¥½
    user_ratios = get_user_ratios()
    user_topics = get_user_topics()
    
    print(f"\nğŸ“Š æ¨èæ¯”ä¾‹: {user_ratios}")
    print(f"ğŸ“š çƒ­é—¨ä¸»é¢˜: {user_topics}")
    
    # è·å–æ–‡ç« 
    articles = fetch_articles()
    
    if not articles:
        print("\nâŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ–‡ç« ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
        # ä½¿ç”¨æµ‹è¯•æ•°æ®
        from daily_tech_digest_simple import generate_test_digest
        digest = generate_test_digest()
    else:
        # é€‰æ‹©æ–‡ç« 
        selected_articles = select_articles(articles, user_ratios, user_topics)
        
        # ç”Ÿæˆæ‘˜è¦
        digest = generate_digest(selected_articles, user_topics)
    
    print("\nğŸ“ æ‘˜è¦ç”Ÿæˆå®Œæˆ")
    print(digest)

if __name__ == "__main__":
    import os
    main()
