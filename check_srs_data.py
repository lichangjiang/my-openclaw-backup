#!/usr/bin/env python3
"""
æ£€æŸ¥ SRS Word æ•°æ®åº“ä¸­çš„æ‰€æœ‰å•è¯å’Œå¥å­çš„æ‹¼å†™å’Œç¿»è¯‘
"""

import psycopg2
from datetime import datetime

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'dbname': 'srs-db',
    'user': 'jolin',
    'password': 'lcj890712',
    'host': '127.0.0.1',
    'port': '5432',
}

def check_database_data():
    """è¿æ¥æ•°æ®åº“å¹¶æ£€æŸ¥æ‰€æœ‰æ•°æ®"""

    try:
        # è¿æ¥æ•°æ®åº“
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        print("=" * 80)
        print("SRS Word æ•°æ®æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 80)
        print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        print()

        # æŸ¥è¯¢æ‰€æœ‰æ•°æ®
        query = """
        SELECT
            id,
            item_type,
            content,
            phonetic_symbol,
            definition,
            translation,
            created_at
        FROM knowledge_items
        ORDER BY item_type, content
        """

        cursor.execute(query)
        items = cursor.fetchall()

        if not items:
            print("âš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•æ•°æ®ï¼")
            return

        print(f"ğŸ“Š æ€»æ¡ç›®æ•°: {len(items)}")
        print()

        # ç»Ÿè®¡
        word_count = 0
        sentence_count = 0

        # æ£€æŸ¥æ•°æ®
        print("=" * 80)
        print("ğŸ“ è¯¦ç»†å†…å®¹")
        print("=" * 80)
        print()

        for item in items:
            (item_id, item_type, content, phonetic_symbol, definition, translation, created_at) = item

            if item_type == 'word':
                word_count += 1
                print(f"ã€å•è¯ {word_count}ã€‘")
                print(f"  ID: {item_id}")
                print(f"  å•è¯: {content}")
                if phonetic_symbol:
                    print(f"  éŸ³æ ‡: {phonetic_symbol}")
                if definition:
                    print(f"  å®šä¹‰: {definition}")
                else:
                    print(f"  âš ï¸  å®šä¹‰ç¼ºå¤±ï¼")
                print(f"  åˆ›å»ºæ—¶é—´: {created_at}")
                print()

                # åŸºæœ¬æ‹¼å†™æ£€æŸ¥
                if not content.isalpha() and '-' not in content and "'" not in content:
                    print(f"  âš ï¸  å¯èƒ½åŒ…å«éå­—æ¯å­—ç¬¦: {content}")

            elif item_type == 'sentence':
                sentence_count += 1
                print(f"ã€å¥å­ {sentence_count}ã€‘")
                print(f"  ID: {item_id}")
                print(f"  å¥å­: {content}")
                if translation:
                    print(f"  ç¿»è¯‘: {translation}")
                else:
                    print(f"  âš ï¸  ç¿»è¯‘ç¼ºå¤±ï¼")
                print(f"  åˆ›å»ºæ—¶é—´: {created_at}")
                print()

                # åŸºæœ¬æ£€æŸ¥
                if not translation:
                    print(f"  âš ï¸  ç¿»è¯‘ç¼ºå¤±ï¼")

            print("-" * 80)
            print()

        # è¾“å‡ºç»Ÿè®¡
        print("=" * 80)
        print("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 80)
        print(f"å•è¯æ€»æ•°: {word_count}")
        print(f"å¥å­æ€»æ•°: {sentence_count}")
        print(f"æ€»è®¡: {len(items)}")
        print()

        # è¾“å‡ºåˆ°æ–‡ä»¶
        output_file = f"/home/lichangjiang/.openclaw/workspace/srs_data_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("SRS Word æ•°æ®æ£€æŸ¥æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n")
            f.write(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"æ€»æ¡ç›®æ•°: {len(items)}\n")
            f.write(f"å•è¯æ€»æ•°: {word_count}\n")
            f.write(f"å¥å­æ€»æ•°: {sentence_count}\n\n")

            for item in items:
                (item_id, item_type, content, phonetic_symbol, definition, translation, created_at) = item

                if item_type == 'word':
                    f.write(f"ã€å•è¯ã€‘\n")
                    f.write(f"  ID: {item_id}\n")
                    f.write(f"  å•è¯: {content}\n")
                    if phonetic_symbol:
                        f.write(f"  éŸ³æ ‡: {phonetic_symbol}\n")
                    if definition:
                        f.write(f"  å®šä¹‰: {definition}\n")
                    else:
                        f.write(f"  âš ï¸ å®šä¹‰ç¼ºå¤±ï¼\n")
                    f.write(f"  åˆ›å»ºæ—¶é—´: {created_at}\n\n")
                elif item_type == 'sentence':
                    f.write(f"ã€å¥å­ã€‘\n")
                    f.write(f"  ID: {item_id}\n")
                    f.write(f"  å¥å­: {content}\n")
                    if translation:
                        f.write(f"  ç¿»è¯‘: {translation}\n")
                    else:
                        f.write(f"  âš ï¸ ç¿»è¯‘ç¼ºå¤±ï¼\n")
                    f.write(f"  åˆ›å»ºæ—¶é—´: {created_at}\n\n")

        print(f"âœ… æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

        # å…³é—­è¿æ¥
        cursor.close()
        conn.close()

    except psycopg2.Error as e:
        print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == '__main__':
    check_database_data()
