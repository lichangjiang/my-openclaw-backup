#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import datetime
import feedparser
import subprocess
import signal
from typing import List, Dict
import time
from datetime import timezone, timedelta
from email.utils import parsedate_to_datetime

# é…ç½®
RSS_SOURCES = {
    "bestblogs_featured": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?featured=y",
        "name": "BestBlogs ç²¾é€‰",
        "category": "programming",
    },
    "bestblogs_programming": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=programming&type=article",
        "name": "BestBlogs ç¼–ç¨‹æŠ€æœ¯",
        "category": "programming",
    },
    "bestblogs_ai": {
        "url": "https://www.bestblogs.dev/en/feeds/rss?category=ai&minScore=90",
        "name": "BestBlogs AI é«˜åˆ†",
        "category": "ai",
    },
    "bestblogs_product": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=product",
        "name": "BestBlogs äº§å“è®¾è®¡",
        "category": "product",
    },
    "hacker_news": {
        "url": "https://hnrss.org/frontpage",
        "name": "Hacker News",
        "category": "programming",
    },
    "reddit_programming": {
        "url": "https://www.reddit.com/r/programming/.rss",
        "name": "Reddit r/programming",
        "category": "programming",
    },
    "openai_blog": {
        "url": "https://openai.com/blog/rss.xml",
        "name": "OpenAI Blog",
        "category": "ai",
    },
}

USER_PREFERENCES_FILE = "/home/lichangjiang/.openclaw/workspace/user_preferences.json"
ARTICLES_PER_DAY = 10
DEFAULT_RATIOS = {"programming": 3, "ai": 5, "product": 2}
TEST_MODE = "--test" in sys.argv

def load_user_preferences() -> Dict:
    try:
        if os.path.exists(USER_PREFERENCES_FILE):
            with open(USER_PREFERENCES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ç”¨æˆ·åå¥½å¤±è´¥: {e}")
        return {}

def get_user_ratios() -> Dict[str, int]:
    preferences = load_user_preferences()
    clicks = preferences.get('clicks', [])
    if not clicks:
        return DEFAULT_RATIOS.copy()
    
    category_counts = {"programming": 0, "ai": 0, "product": 0}
    for click in clicks:
        category = click.get('category', 'unknown')
        if category in category_counts:
            category_counts[category] += 1
            
    total_clicks = sum(category_counts.values()) or 1
    if total_clicks == 0:
        return DEFAULT_RATIOS.copy()
        
    ratios = {}
    for category, count in category_counts.items():
        articles = (count / total_clicks) * ARTICLES_PER_DAY
        ratios[category] = max(2, round(articles))
    return ratios

def parse_pub_time(pub_date: str) -> datetime.datetime:
    """è§£æå‘å¸ƒæ—¶é—´"""
    try:
        # ä½¿ç”¨ email.utils.parsedate_to_datetime è§£æ RFC 2822 æ ¼å¼
        dt = parsedate_to_datetime(pub_date)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except Exception as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è§£æ
        for fmt in [
            '%a, %d %b %Y %H:%M:%S %Z',
            '%a, %d %b %Y %H:%M:%S %z',
            '%Y-%m-%dT%H:%M:%SZ',
            '%Y-%m-%dT%H:%M:%S%z',
        ]:
            try:
                dt = datetime.datetime.strptime(pub_date, fmt)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt
            except:
                continue
    return None

def get_user_topics() -> List[str]:
    preferences = load_user_preferences()
    clicks = preferences.get('clicks', [])
    topic_counts = {}
    
    keywords = ['python', 'rust', 'go', 'java', 'react', 'vue', 'docker',
                'kubernetes', 'k8s', 'ai', 'ml', 'security', 'linux']
    
    for click in clicks:
        title = click.get('title', '')
        for keyword in keywords:
            if keyword.lower() in title.lower():
                topic_counts[keyword] = topic_counts.get(keyword, 0) + 1
                
    sorted_topics = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    return [topic for topic, count in sorted_topics]

def calculate_score(article: Dict, user_topics: List[str]) -> int:
    score = 50  # åŸºç¡€åˆ†
    
    # æ—¶é—´æ–°é²œåº¦ï¼ˆè¶Šæ–°è¶Šå¥½ï¼‰
    pub_time = article.get('pub_time')
    if pub_time:
        now = datetime.datetime.now(timezone.utc)
        hours_old = (now - pub_time).total_seconds() / 3600
        if hours_old < 24:
            score += 20  # 24å°æ—¶å†…
        elif hours_old < 48:
            score += 15  # 48å°æ—¶å†…
        elif hours_old < 72:
            score += 10  # 72å°æ—¶å†…
    
    # ä¸»é¢˜ç›¸å…³åº¦
    for topic in user_topics:
        if topic.lower() in article.get('title', '').lower():
            score += 20
            
    # æ¥æºä¼˜å…ˆçº§
    source = article.get('source', '')
    if 'featured' in source:
        score += 15
    elif 'ai' in source:
        score += 10
    elif 'hacker' in source:
        score += 8
        
    return score

def fetch_articles() -> List[Dict]:
    all_articles = []
    print("ğŸ“¡ æ­£åœ¨è·å– RSS æº...")
    
    # åªè·å–æœ€è¿‘ 3 å¤©çš„æ–‡ç« 
    now = datetime.datetime.now(timezone.utc)
    cutoff_time = now - timedelta(days=3)
    
    for source_key, source_config in RSS_SOURCES.items():
        try:
            print(f"  â†’ {source_config['name']}")
            feed = feedparser.parse(source_config['url'])
            
            fresh_count = 0
            for entry in feed.entries:
                article = {
                    'title': entry.get('title', ''),
                    'link': entry.get('link', ''),
                    'published': entry.get('published', ''),
                    'source': source_key,
                    'category': source_config['category'],
                }
                
                # è§£æå‘å¸ƒæ—¶é—´
                pub_time = parse_pub_time(article['published'])
                article['pub_time'] = pub_time
                
                # åªä¿ç•™æœ€è¿‘ 3 å¤©çš„æ–‡ç« 
                if pub_time and pub_time > cutoff_time:
                    all_articles.append(article)
                    fresh_count += 1
                elif not pub_time:
                    # å¦‚æœæ— æ³•è§£ææ—¶é—´ï¼Œä¹Ÿä¿ç•™ï¼ˆä½†ä¸è®¡å…¥æ–°é²œåº¦ï¼‰
                    all_articles.append(article)
                
            print(f"     âœ“ è·å– {len(feed.entries)} ç¯‡ï¼Œæ–°é²œ {fresh_count} ç¯‡")
                
        except Exception as e:
            print(f"  âš ï¸ {source_config['name']} è·å–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"âœ… å…±è·å– {len(all_articles)} ç¯‡æ–‡ç« ï¼ˆæœ€è¿‘ 3 å¤©ï¼‰")
    return all_articles

def select_articles(articles: List[Dict], user_ratios: Dict[str, int], user_topics: List[str]) -> Dict[str, List[Dict]]:
    for article in articles:
        article['score'] = calculate_score(article, user_topics)
    
    articles.sort(key=lambda x: x['score'], reverse=True)
    
    selected_articles = {"programming": [], "ai": [], "product": []}
    
    for article in articles:
        category = article.get('category', 'programming')
        if category in selected_articles:
            if len(selected_articles[category]) < user_ratios.get(category, 3):
                selected_articles[category].append(article)
                
    total = sum(len(v) for v in selected_articles.values())
    if total < ARTICLES_PER_DAY:
        for article in articles:
            if not any(article in v for v in selected_articles.values()):
                category = article.get('category', 'programming')
                if category in selected_articles:
                    selected_articles[category].append(article)
                    if sum(len(v) for v in selected_articles.values()) >= ARTICLES_PER_DAY:
                        break
                        
    return selected_articles

def generate_digest(selected_articles: Dict[str, List[Dict]], user_topics: List[str]) -> str:
    now = datetime.datetime.now(datetime.timezone.utc)
    beijing_time = now + datetime.timedelta(hours=8)
    date_str = beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    digest = f"ğŸ“… {date_str} æ¯æ—¥æŠ€æœ¯æ‘˜è¦\n\n"
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    digest += f"ğŸ”¥ ä»Šæ—¥ç²¾é€‰ï¼ˆ{sum(len(v) for v in selected_articles.values())} ç¯‡ï¼‰\n\n"
    
    categories = [
        ("programming", "ğŸ’» ç¼–ç¨‹æŠ€æœ¯"),
        ("ai", "ğŸ¤– AI å‰æ²¿"),
        ("product", "ğŸ¨ äº§å“è®¾è®¡")
    ]
    
    for cat_key, cat_name in categories:
        articles = selected_articles.get(cat_key, [])
        if not articles: continue
        
        digest += f"### {cat_name}ï¼ˆ{len(articles)} ç¯‡ï¼‰\n\n"
        for i, article in enumerate(articles[:5], 1):
            digest += f"{i}. **{article['title'][:60]}...**\n"
            digest += f"   * æ¥æºï¼š{RSS_SOURCES.get(article['source'], {}).get('name', 'Unknown')}\n"
            
            # æ˜¾ç¤ºå‘å¸ƒæ—¶é—´
            pub_time = article.get('pub_time')
            if pub_time:
                beijing_pub = pub_time + datetime.timedelta(hours=8)
                time_str = beijing_pub.strftime("%mæœˆ%dæ—¥ %H:%M")
                hours_old = int((now - pub_time).total_seconds() / 3600)
                if hours_old < 1:
                    time_str += " (åˆšåˆš)"
                elif hours_old < 24:
                    time_str += f" ({hours_old}å°æ—¶å‰)"
                else:
                    time_str += f" ({hours_old//24}å¤©å‰)"
                digest += f"   * å‘å¸ƒï¼š{time_str}\n"
            else:
                digest += f"   * å‘å¸ƒï¼š{article.get('published', 'N/A')[:20]}...\n"
            
            digest += f"   * é“¾æ¥ï¼š{article['link']}\n\n"
    
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ ä¸ªæ€§åŒ–æç¤º\n"
    digest += f"**çƒ­é—¨ä¸»é¢˜ï¼š** {', '.join(user_topics) if user_topics else 'æš‚æ— æ•°æ®'}\n"
    digest += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\næ¥æºï¼šBestBlogs.dev + å…¶ä»–ç²¾é€‰æº"
    
    return digest

def trigger_openglaw_send(digest: str) -> bool:
    """è§¦å‘ OpenClaw å‘é€æ¶ˆæ¯ï¼ˆæ–¹æ¡ˆ1ï¼šç›´æ¥è°ƒç”¨ APIï¼‰"""
    try:
        # å°†æ‘˜è¦å†™å…¥ä¸´æ—¶æ–‡ä»¶
        temp_file = "/tmp/daily_tech_digest_content.txt"
        with open(temp_file, 'w', encoding='utf-8') as f:
            f.write(digest)
        
        print(f"âœ… æ‘˜è¦å·²ä¿å­˜åˆ°: {temp_file}")
        print(f"ğŸ“¤ æ‘˜è¦å†…å®¹å·²è¾“å‡ºï¼Œç­‰å¾… OpenClaw è‡ªåŠ¨å‘é€...")
        
        # è¾“å‡ºç‰¹å®šæ ‡è®°ï¼Œè®© OpenClaw æ•è·å¹¶å‘é€
        print(f"\nã€OpenClaw_SEND_STARTã€‘")
        print(digest)
        print(f"ã€OpenClaw_SEND_ENDã€‘\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‘é€å¤±è´¥: {e}")
        return False

def main():
    print("ğŸš€ æ¯æ—¥æŠ€æœ¯æ‘˜è¦æ¨é€ç³»ç»Ÿå¯åŠ¨")
    print("=" * 50)
    
    user_ratios = get_user_ratios()
    user_topics = get_user_topics()
    
    print(f"\nğŸ“Š æ¨èæ¯”ä¾‹: {user_ratios}")
    print(f"ğŸ“š çƒ­é—¨ä¸»é¢˜: {user_topics}")
    
    articles = fetch_articles()
    selected_articles = select_articles(articles, user_ratios, user_topics)
    digest = generate_digest(selected_articles, user_topics)
    
    if TEST_MODE:
        print("\nğŸ§ª æµ‹è¯•æ¨¡å¼:\n")
        print(digest)
        return
    
    print("\nğŸ“ ç”Ÿæˆæ‘˜è¦å®Œæˆï¼Œå‡†å¤‡å‘é€...")
    
    # è§¦å‘ OpenClaw å‘é€
    success = trigger_openglaw_send(digest)
    
    if success:
        print("\nâœ… æ¨é€ä»»åŠ¡å·²å®Œæˆ")
    else:
        print("\nâŒ æ¨é€ä»»åŠ¡å¤±è´¥")

if __name__ == "__main__":
    main()
