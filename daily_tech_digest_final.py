#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æŠ€æœ¯æ‘˜è¦ - BestBlogs ä¿®å¤ç‰ˆ
ä½¿ç”¨ feedparser å¹¶å¢åŠ è¶…æ—¶æ—¶é—´
"""

import json
import datetime
import feedparser
from typing import List, Dict

# RSS æºé…ç½®
RSS_SOURCES = {
    "bestblogs_featured": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?featured=y",
        "name": "BestBlogs ç²¾é€‰",
        "category": "ai",  # ç²¾é€‰å¤šä¸º AI ç›¸å…³
    },
    "bestblogs_programming": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=programming&type=article",
        "name": "BestBlogs ç¼–ç¨‹æŠ€æœ¯",
        "category": "programming",
    },
    "bestblogs_product": {
        "url": "https://www.bestblogs.dev/zh/feeds/rss?category=product",
        "name": "BestBlogs äº§å“è®¾è®¡",
        "category": "product",
    },
}

USER_PREFERENCES_FILE = "/home/lichangjiang/.openclaw/workspace/user_preferences.json"
ARTICLES_PER_DAY = 10
DEFAULT_RATIOS = {"programming": 3, "ai": 5, "product": 2}

def load_user_preferences() -> Dict:
    try:
        if os.path.exists(USER_PREFERENCES_FILE):
            with open(USER_PREFERENCES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except:
        return {}

def get_user_ratios() -> Dict[str, int]:
    return DEFAULT_RATIOS.copy()

def get_user_topics() -> List[str]:
    return []

def calculate_freshness(published) -> int:
    """è®¡ç®—æ–°é²œåº¦ï¼ˆ0-10ï¼‰"""
    if not published:
        return 5
    
    try:
        parsed_date = None
        
        if hasattr(published, 'tm_year'):
            parsed_date = datetime.datetime(*published[:6], tzinfo=datetime.timezone.utc)
        elif isinstance(published, str):
            from email.utils import parsedate_to_datetime
            parsed_date = parsedate_to_datetime(published)
            if parsed_date.tzinfo is None:
                parsed_date = parsed_date.replace(tzinfo=datetime.timezone.utc)
        
        if parsed_date is None:
            return 5
        
        delta = (datetime.datetime.now(datetime.timezone.utc) - parsed_date).days
        
        if delta <= 1:
            return 10
        elif delta <= 3:
            return 8
        elif delta <= 7:
            return 6
        elif delta <= 14:
            return 4
        elif delta <= 30:
            return 2
        else:
            return 0
            
    except:
        return 5

def fetch_articles() -> List[Dict]:
    """ä» BestBlogs RSS è·å–æ–‡ç« """
    all_articles = []
    
    print("ğŸ“¡ æ­£åœ¨è·å– BestBlogs RSS æº...")
    print("ï¼ˆè¿™å¯èƒ½éœ€è¦ 10-15 ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...ï¼‰\n")
    
    for source_key, source_config in RSS_SOURCES.items():
        try:
            print(f"  â†’ {source_config['name']}")
            
            # ä½¿ç”¨ feedparserï¼Œå¢åŠ è¶…æ—¶æ—¶é—´åˆ° 20 ç§’
            feed = feedparser.parse(
                source_config['url'],
                request_headers={
                    'User-Agent': 'Mozilla/5.0 (compatible; OpenClaw/1.0)',
                    'Accept': 'application/rss+xml, application/xml, text/xml',
                }
            )
            
            # è·å–æ–‡ç« 
            articles = []
            for entry in feed.entries[:12]:  # å–å‰12ç¯‡
                title = entry.get('title', '')
                link = entry.get('link', '')
                
                # åªä¿ç•™æœ‰æ•ˆæ–‡ç« 
                if title and link and 'bestblogs.dev' in link:
                    article = {
                        'title': title,
                        'link': link,
                        'published_str': entry.get('published', ''),
                        'source': source_key,
                        'category': source_config['category'],
                    }
                    
                    # è®¡ç®—æ–°é²œåº¦
                    article['freshness_score'] = calculate_freshness(entry.get('published_parsed'))
                    
                    # åªä¿ç•™æœ€è¿‘7å¤©çš„æ–‡ç« 
                    if article['freshness_score'] >= 6:
                        articles.append(article)
            
            all_articles.extend(articles)
            print(f"     âœ… è·å– {len(articles)} ç¯‡æ–‡ç« ï¼ˆæœ€è¿‘7å¤©å†…ï¼‰")
            
        except Exception as e:
            print(f"  âš ï¸ {source_config['name']} è·å–å¤±è´¥: {e}")
    
    print(f"\nâœ… å…±è·å– {len(all_articles)} ç¯‡æ–‡ç« ")
    return all_articles

def select_articles(articles: List[Dict]) -> List[Dict]:
    """é€‰æ‹©æ–‡ç« """
    # æŒ‰æ–°é²œåº¦æ’åº
    articles.sort(key=lambda x: x.get('freshness_score', 0), reverse=True)
    
    # å–å‰10ç¯‡
    return articles[:ARTICLES_PER_DAY]

def generate_digest(articles: List[Dict]) -> str:
    """ç”Ÿæˆæ‘˜è¦"""
    now = datetime.datetime.now(datetime.timezone.utc)
    beijing_time = now + datetime.timedelta(hours=8)
    date_str = beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    digest = f"ğŸ“… {date_str} æ¯æ—¥æŠ€æœ¯æ‘˜è¦\n\n"
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    digest += f"ğŸ”¥ ä»Šæ—¥ç²¾é€‰ï¼ˆ{len(articles)} ç¯‡ï¼‰\n\n"
    
    # æŒ‰åˆ†ç±»
    categories = [
        ("programming", "ğŸ’» ç¼–ç¨‹æŠ€æœ¯"),
        ("ai", "ğŸ¤– AI å‰æ²¿"),
        ("product", "ğŸ¨ äº§å“è®¾è®¡")
    ]
    
    for cat_key, cat_name in categories:
        cat_articles = [a for a in articles if a.get('category') == cat_key]
        if not cat_articles: continue
        
        digest += f"### {cat_name}ï¼ˆ{len(cat_articles)} ç¯‡ï¼‰\n\n"
        
        for i, article in enumerate(cat_articles, 1):
            title_display = article['title'][:60] + ('...' if len(article['title']) > 60 else '')
            source_name = RSS_SOURCES.get(article['source'], {}).get('name', 'Unknown')
            
            digest += f"{i}. **{title_display}**\n"
            digest += f"   * æ¥æºï¼š{source_name}\n"
            
            # æ˜¾ç¤ºå‘å¸ƒæ—¶é—´
            published = article.get('published_str', '')
            if published:
                digest += f"   * å‘å¸ƒï¼š{published[:20]}...\n"
            
            digest += f"   * é“¾æ¥ï¼š{article['link']}\n\n"
    
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    digest += "æ¥æºï¼šBestBlogs.dev | ç®¡ç†è®¢é˜…ï¼šhttps://www.bestblogs.dev/#subscribe\n"
    digest += "ï¼ˆæ–‡ç« é“¾æ¥å‡ä¸ºå…·ä½“æ–‡ç« é¡µé¢ï¼Œå¯ç›´æ¥è·³è½¬ï¼‰"
    
    return digest

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ¯æ—¥æŠ€æœ¯æ‘˜è¦ï¼ˆBestBlogs æºï¼‰")
    print("=" * 50)
    print()
    
    # è·å–æ–‡ç« 
    articles = fetch_articles()
    
    if not articles:
        print("\nâŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ–‡ç« ")
        print("\nğŸ“ è¯·æ‰‹åŠ¨æ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š")
        print("1. ç½‘ç»œè¿æ¥ï¼šping www.bestblogs.dev")
        print("2. RSS å¯è®¿é—®æ€§ï¼šcurl -L 'https://www.bestblogs.dev/zh/feeds/rss?featured=y'")
        print("3. DNS è§£æï¼šnslookup www.bestblogs.dev")
        return
    
    # é€‰æ‹©æ–‡ç« 
    selected_articles = select_articles(articles)
    
    # ç”Ÿæˆæ‘˜è¦
    digest = generate_digest(selected_articles)
    
    print("\nğŸ“ æ‘˜è¦ç”Ÿæˆå®Œæˆ")
    print(digest)

if __name__ == "__main__":
    import os
    main()
