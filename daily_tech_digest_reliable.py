#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥æŠ€æœ¯æ‘˜è¦ç”Ÿæˆè„šæœ¬ - å¯é ç‰ˆ
ä½¿ç”¨ Hacker News å’Œå…¶ä»–å¯é  RSS æº
"""

import json
import datetime
import feedparser
from typing import List, Dict

# ä½¿ç”¨å¯é çš„ RSS æº
RSS_SOURCES = {
    "hacker_news": {
        "url": "https://hnrss.org/frontpage",
        "name": "Hacker News",
        "category": "programming",
    },
    "github_trending": {
        "url": "https://github.com/trending/developers.atom",
        "name": "GitHub Trending Developers",
        "category": "programming",
    },
}

USER_PREFERENCES_FILE = "/home/lichangjiang/.openclaw/workspace/user_preferences.json"
ARTICLES_PER_DAY = 10
DEFAULT_RATIOS = {"programming": 5, "ai": 5, "product": 0}

def load_user_preferences() -> Dict:
    try:
        if os.path.exists(USER_PREFERENCES_FILE):
            with open(USER_PREFERENCES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    except:
        return {}

def get_user_ratios() -> Dict[str, int]:
    return DEFAULT_RATIOS.copy()

def get_user_topics() -> List[str]:
    return []

def fetch_articles() -> List[Dict]:
    """ä» RSS æºè·å–æ–‡ç« """
    all_articles = []
    
    print("ğŸ“¡ æ­£åœ¨è·å– RSS æº...")
    
    for source_key, source_config in RSS_SOURCES.items():
        try:
            print(f"  â†’ {source_config['name']}")
            
            # ä½¿ç”¨ feedparserï¼ˆä¸ä½¿ç”¨ç§æœ‰ APIï¼‰
            feed = feedparser.parse(source_config['url'])
            
            articles = []
            for entry in feed.entries[:10]:  # å–å‰10ç¯‡
                article = {
                    'title': entry.get('title', ''),
                    'link': entry.get('link', ''),
                    'published_str': entry.get('published', ''),
                    'source': source_key,
                    'category': source_config['category'],
                }
                
                articles.append(article)
            
            all_articles.extend(articles)
            print(f"     âœ… è·å– {len(articles)} ç¯‡æ–‡ç« ")
            
        except Exception as e:
            print(f"  âš ï¸ {source_config['name']} è·å–å¤±è´¥: {e}")
    
    print(f"âœ… å…±è·å– {len(all_articles)} ç¯‡æ–‡ç« ")
    return all_articles

def generate_digest(articles: List[Dict]) -> str:
    """ç”Ÿæˆæ‘˜è¦"""
    now = datetime.datetime.now(datetime.timezone.utc)
    beijing_time = now + datetime.timedelta(hours=8)
    date_str = beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    digest = f"ğŸ“… {date_str} æ¯æ—¥æŠ€æœ¯æ‘˜è¦\n\n"
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    digest += f"ğŸ”¥ ä»Šæ—¥ç²¾é€‰ï¼ˆ{len(articles)} ç¯‡ï¼‰\n\n"
    
    digest += f"### ğŸ’» ç¼–ç¨‹æŠ€æœ¯ï¼ˆ{len(articles)} ç¯‡ï¼‰\n\n"
    
    for i, article in enumerate(articles, 1):
        title_display = article['title'][:60] + ('...' if len(article['title']) > 60 else '')
        source_name = RSS_SOURCES.get(article['source'], {}).get('name', 'Unknown')
        
        digest += f"{i}. **{title_display}**\n"
        digest += f"   * æ¥æºï¼š{source_name}\n"
        
        # æ˜¾ç¤ºå‘å¸ƒæ—¶é—´
        published = article.get('published_str', '')
        if published:
            digest += f"   * å‘å¸ƒï¼š{published[:20]}...\n"
        
        digest += f"   * é“¾æ¥ï¼š{article['link']}\n\n"
    
    digest += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ ä¸ªæ€§åŒ–æç¤º\n"
    digest += "**çƒ­é—¨ä¸»é¢˜ï¼š** æš‚æ— æ•°æ®ï¼ˆéœ€è¦å¤šç‚¹å‡»ç§¯ç´¯æ•°æ®ï¼‰\n"
    digest += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\næ¥æºï¼šHacker News + GitHub | å®æ—¶æ›´æ–°"
    
    return digest

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ¯æ—¥æŠ€æœ¯æ‘˜è¦æ¨é€ç³»ç»Ÿï¼ˆå¯é ç‰ˆï¼‰")
    print("=" * 50)
    
    # è·å–æ–‡ç« 
    articles = fetch_articles()
    
    if not articles:
        print("\nâŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ–‡ç« ")
        return
    
    # ç”Ÿæˆæ‘˜è¦
    digest = generate_digest(articles)
    
    print("\nğŸ“ æ‘˜è¦ç”Ÿæˆå®Œæˆ")
    print(digest)

if __name__ == "__main__":
    import os
    main()
